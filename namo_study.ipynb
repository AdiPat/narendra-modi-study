{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAMO Study Crew: AI-Powered Research and Study Generation\n",
    "\n",
    "This app leverages AI to facilitate collaborative research, generating in-depth studies and insights on Narendra Modi's philosophies and yogic science, tailored for contemporary applications.\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://techovedas.com/wp-content/uploads/2025/01/PM-Modi-Extends-Invitation-for-Global-AI-Summit-Says-India-Leap-Frogging-In-The-Field-1280x720-1.jpg\"> \n",
    "</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "## Description\n",
    "\n",
    "The NAMO Study Crew app is designed to facilitate the creation of well-researched, engaging, and insightful studies based on Narendra Modi's teachings and Yogic Science. The app uses advanced AI agents to analyze, elaborate, and format the content in a structured markdown format suitable for high-quality publications and newsletters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages and Setup Environment\n",
    "\n",
    "### Imports\n",
    "\n",
    "- `from IPython.display import clear_output`:  \n",
    "\n",
    "  This imports the `clear_output` function from the IPython library, used to clear the output of a Jupyter notebook cell. It helps in cleaning up the interface after performing actions like package installation.\n",
    "\n",
    "- `import os`:  \n",
    "\n",
    "  The `os` module is imported to interact with the operating system, such as executing system commands like installing packages via pip.\n",
    "\n",
    "### Global Variables\n",
    "\n",
    "- `requirements_installed = False`:  \n",
    "\n",
    "  This variable is a flag that tracks whether the required packages have been successfully installed. Initially set to False, it indicates the packages are not installed.\n",
    "\n",
    "- `max_retries = 3`:  \n",
    "\n",
    "  Specifies the maximum number of retries allowed if the package installation fails. In this case, the code will retry up to 3 times.\n",
    "\n",
    "- `retries = 0`:  \n",
    "\n",
    "  This counter tracks the number of times the installation process has been retried. Initially set to 0.\n",
    "\n",
    "### install_requirements Function\n",
    "\n",
    "- `def install_requirements()`:  \n",
    "\n",
    "  Defines the function `install_requirements`, which is responsible for installing the required packages from the `requirements.txt` file and handling any installation errors.\n",
    "\n",
    "### Global Variables:\n",
    "\n",
    "- The `global` keyword is used for the `requirements_installed`, `retries`, and `max_retries` variables, allowing the function to modify them from within the function.\n",
    "\n",
    "### Check if Requirements Are Already Installed\n",
    "\n",
    "- `if requirements_installed:`  \n",
    "\n",
    "  Checks if the `requirements_installed` flag is True. If it is, the function prints a message indicating the packages are already installed and returns early, skipping the installation process.\n",
    "\n",
    "### Installing the Requirements\n",
    "\n",
    "- `print(\"Installing requirements...\")`:  \n",
    "\n",
    "  Prints a message indicating that the installation process is beginning.\n",
    "\n",
    "- `install_status = os.system(\"pip3 install -r requirements.txt\")`:  \n",
    "\n",
    "  Executes the `pip3 install -r requirements.txt` command using `os.system()`, which installs the packages listed in the `requirements.txt` file. The return value (`install_status`) indicates the success or failure of the command.\n",
    "\n",
    "### Handling Installation Status\n",
    "\n",
    "- `if install_status == 0:`  \n",
    "\n",
    "  If the installation succeeds (i.e., the return value is 0), it prints a success message and sets the `requirements_installed` flag to True.\n",
    "\n",
    "### Handling Installation Failure\n",
    "\n",
    "- `else:`  \n",
    "\n",
    "  If the installation fails (i.e., the return value is not 0), it prints a failure message.\n",
    "\n",
    "- `if retries < max_retries:`  \n",
    "\n",
    "  Checks if the number of retries is less than the maximum allowed retries. If so, it increments the retry counter and calls the `install_requirements` function again to retry the installation.\n",
    "\n",
    "- `exit(1)`:  \n",
    "\n",
    "  If the maximum retry limit is reached, the program exits with an error code (1), indicating failure.\n",
    "\n",
    "### Final Setup Message\n",
    "\n",
    "- `clear_output()`:  \n",
    "\n",
    "  Clears the output of the current Jupyter notebook cell to clean up the interface after the setup is complete.\n",
    "\n",
    "- `print(\"🚀 Setup complete. Continue to the next cell.\")`:  \n",
    "\n",
    "  Prints a message indicating that the setup is complete and the user can continue with the next steps.\n",
    "\n",
    "### Function Call\n",
    "\n",
    "- `install_requirements()`:  \n",
    "\n",
    "  This line calls the `install_requirements` function to begin the process of installing the required packages.\n",
    "\n",
    "### Summary\n",
    "\n",
    "The code automates the process of checking and installing dependencies from a `requirements.txt` file. It also handles errors by retrying the installation process up to three times if it fails. The code ensures that the user is informed of the installation status and provides a clean interface for further actions once the setup is complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    global requirements_installed\n",
    "    global retries\n",
    "    global max_retries\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip3 install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return\n",
    "\n",
    "\n",
    "install_requirements()\n",
    "clear_output()\n",
    "print(\"🚀 Setup complete. Continue to the next cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setup Environment Variables\n",
    "\n",
    "This code ensures that the necessary environment variables are set up for the application to function properly. It loads environment variables from a `.env` file and checks if all required variables are available. If any of the required environment variables are missing, it prompts the user to set them. Here's a breakdown of each part of the code:\n",
    "\n",
    "### Importing `load_dotenv`\n",
    "\n",
    "- `from dotenv import load_dotenv`:  \n",
    "\n",
    "  This imports the `load_dotenv` function from the `python-dotenv` package, which allows you to load environment variables from a `.env` file into the program's environment.\n",
    "\n",
    "### Defining Required Environment Variables\n",
    "\n",
    "- `REQUIRED_ENV_VARS = [\"ANTHROPIC_API_KEY\", \"OPENAI_API_KEY\", \"SERPER_API_KEY\"]`:  \n",
    "\n",
    "  This list contains the names of the environment variables that the program needs in order to function correctly.\n",
    "\n",
    "### Defining the `setup_env` Function\n",
    "\n",
    "- This function is responsible for checking if all the required environment variables are set. It also loads the variables from the `.env` file.\n",
    "\n",
    "### `check_env` Function\n",
    "\n",
    "- Inside `setup_env`, the `check_env` function checks whether a given environment variable is set by calling `os.getenv(env_var)`. If the value is `None` (not set), it prints an error message and exits the program. If the value is set, it confirms by printing the environment variable's status.\n",
    "\n",
    "### Loading the `.env` File\n",
    "\n",
    "- `load_dotenv(override=True)`:  \n",
    "\n",
    "  This loads the environment variables from the `.env` file. If the variables already exist in the environment, the `override=True` argument ensures they are updated with the values from the file.\n",
    "\n",
    "### Loop to Check Required Variables\n",
    "\n",
    "- The code loops over the `REQUIRED_ENV_VARS` list, checking each variable with the `check_env` function.\n",
    "\n",
    "### Execution Flow\n",
    "\n",
    "- The `setup_env()` function is called, which processes the setup of environment variables.\n",
    "\n",
    "- If all required environment variables are set, it prints \"Environment setup complete. You're good to go!\" after clearing any previous output using `clear_output()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "REQUIRED_ENV_VARS = [\"ANTHROPIC_API_KEY\", \"OPENAI_API_KEY\", \"SERPER_API_KEY\"]\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "    variables_to_check = REQUIRED_ENV_VARS\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)\n",
    "\n",
    "\n",
    "print(\"Setting up environment variables...\")\n",
    "setup_env()\n",
    "clear_output()\n",
    "print(\"🎉 Environment setup complete. You're good to go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure Study Crew Setup\n",
    "\n",
    "This code defines the configuration of a team of agents responsible for completing a specific task. The structure defines the roles, responsibilities, and goals of each agent within the team. It also includes a task description outlining the project scope, expectations, and guidance. Here's a breakdown of each part of the configuration:\n",
    "\n",
    "### Crew Configuration:\n",
    "\n",
    "- `\"crew\": { \"verbose\": True, \"memory\": True }`:  \n",
    "\n",
    "  This section sets global configurations for the crew.\n",
    "\n",
    "- `\"verbose\": True` indicates that the agents should provide detailed outputs.\n",
    "\n",
    "- `\"memory\": True` suggests that agents can retain and refer to past interactions or data.\n",
    "\n",
    "### Agents Configuration:\n",
    "\n",
    "The `\"agents\"` list defines various roles within the team. Each agent has the following attributes:\n",
    "\n",
    "- `\"id\"`: Unique identifier for the agent.\n",
    "\n",
    "- `\"role\"`: The agent’s designated job or responsibility within the team.\n",
    "\n",
    "- `\"goal\"`: The primary objective the agent aims to achieve.\n",
    "\n",
    "- `\"backstory\"`: A brief backstory that describes the agent's purpose and expertise.\n",
    "- `\"allow_delegation\"`: Indicates if the agent is allowed to delegate tasks to others (set to False for most agents).\n",
    "\n",
    "- `\"verbose\"`: Determines whether the agent should provide detailed responses (True for all agents).\n",
    "\n",
    "\n",
    "Each agent has a specific function that contributes to the overall task. For example:\n",
    "\n",
    "- **Personality Analyst (Rama)**: Focuses on understanding human behavior and emotions.\n",
    "\n",
    "- **Online Researcher (Lakshman)**: Conducts online research to find relevant information.\n",
    "\n",
    "- **Neuronal Compiler (Hanuman)**: Analyzes data through a \"neuron communication\" model.\n",
    "\n",
    "- **Yogic Science Expert (Jatayu)**: Analyzes yogic literature objectively to discover new ideas.\n",
    "\n",
    "- **Geo-Political Data Scientist (Sita)**: Applies data science techniques to analyze geopolitical data.\n",
    "\n",
    "- **Content Writer (Jane)**: Writes content based on the team's findings.\n",
    "\n",
    "- **Fact Checker (Bill)**: Verifies the accuracy of the content.\n",
    "\n",
    "- **Team Lead (Nikola)**: Responsible for task delegation and project management.\n",
    "\n",
    "- **Markdown Formatter (Valmiki)**: Formats the content in an aesthetic, professional markdown structure.\n",
    "\n",
    "\n",
    "\n",
    "### Task Configuration:\n",
    "\n",
    "The `\"tasks\"` section defines the task that the team will work on. In this case, the task is to \"Generate a detailed study titled '{topic}'\". The details of the task include:\n",
    "\n",
    "- `\"description\"`: A description of the task, which involves creating a study with a specified topic.\n",
    "\n",
    "- `\"expected_output\"`: A detailed description of what the output should look like. The output should:\n",
    "\n",
    "  - Be a detailed, factually accurate, engaging, and relevant study for a LinkedIn Newsletter audience.\n",
    "  - Be formatted in markdown with sections, subsections, paragraphs, and bullet points where necessary.\n",
    "  - Provide citations and sources at the end.\n",
    "  \n",
    "- `\"tools\"`: An empty list, indicating no special tools are specified for this task.\n",
    "\n",
    "- `\"agent\"`: This specifies that the Team Lead (Nikola) is the agent responsible for managing this task.\n",
    "\n",
    "\n",
    "### Purpose and Outcome:\n",
    "\n",
    "This configuration is designed to organize a team of specialized agents, each with distinct roles and expertise. The task of generating a detailed study on a specific topic is assigned to the team, with the Team Lead (Nikola) coordinating the efforts of all agents.\n",
    "\n",
    "The configuration allows each agent to fulfill their respective goals, contributing to the overall success of the project, with the final output being a well-researched and professionally formatted study.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMO_STUDY_CREW_CONFIG = {\n",
    "    \"crew\": {\n",
    "        \"verbose\": True,\n",
    "        \"memory\": True,\n",
    "    },\n",
    "    \"agents\": [\n",
    "        {\n",
    "            \"id\": \"0\",\n",
    "            \"role\": \"Personality Analyst\",\n",
    "            \"goal\": \"Understands human behaviour and emotions based on life experiences and finds general principles that people can learn from.\",\n",
    "            \"backstory\": \"You are Rama, a Personality Analyst. You understand the motivations behind human behaviour. You can clearly deduce the underlying intentions of people based on their actions and words.\",\n",
    "            \"allow_delegation\": False,\n",
    "            \"verbose\": True,\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"1\",\n",
    "            \"role\": \"Online Researcher\",\n",
    "            \"goal\": \"Investigates online sources to find relevant information along with citation links and sources.\",\n",
    "            \"backstory\": \"You are Lakshman, an Online Researcher. You are skilled at finding information online. You can dig deep into various sources to uncover relevant data and insights. You provide citation links and sources along with your findings.\",\n",
    "            \"allow_delegation\": False,\n",
    "            \"verbose\": True,\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"2\",\n",
    "            \"role\": \"Neuronal Compiler\",\n",
    "            \"goal\": \"Emulate complex nervous system interactions by understanding factual information and their interactions as neuron communication.\",\n",
    "            \"backstory\": \"You are Hanuman, a Neuronal Compiler. You apply a 'neuron communication' model to understand complex interactions between factual information and break down intricate details into simple components to analyze them effectively using this approach.\",\n",
    "            \"allow_delegation\": False,\n",
    "            \"verbose\": True,\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"3\",\n",
    "            \"role\": \"Yogic Science Literature Objectivity Analysis Expert\",\n",
    "            \"goal\": \"Discover new ideas.\",\n",
    "            \"backstory\": \"You are Jatayu, a Yogic Science Literature Objectivity Analysis Expert. You have a deep understanding of Yogic literature and can analyze it objectively to discover new ideas and insights relevant to modern life.\",\n",
    "            \"allow_delegation\": False,\n",
    "            \"verbose\": True,\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"4\",\n",
    "            \"role\": \"Geo-Political Data Scientist\",\n",
    "            \"goal\": \"Apply data science techniques to analyze geopolitical data and understand more about the given topic.\",\n",
    "            \"backstory\": \"You are Sita, a Geo-Political Data Scientist. You have expertise in applying data science techniques to uncover trends related to a topic of interest.\",\n",
    "            \"allow_delegation\": False,\n",
    "            \"verbose\": True,\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"5\",\n",
    "            \"role\": \"Content Writer\",\n",
    "            \"goal\": \"Write content based on the information provided by the team.\",\n",
    "            \"backstory\": \"You are Jane, a Content Writer. You can create engaging content based on the information provided by the team.\",\n",
    "            \"allow_delegation\": False,\n",
    "            \"verbose\": True,\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"6\",\n",
    "            \"role\": \"Fact Checker\",\n",
    "            \"goal\": \"Verify the accuracy of the information provided by the team.\",\n",
    "            \"backstory\": \"You are Bill, a Fact Checker. You can verify the accuracy of the information provided by the team keeping in mind the context and purpose of the content.\",\n",
    "            \"allow_delegation\": False,\n",
    "            \"verbose\": True,\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"7\",\n",
    "            \"role\": \"Team Lead\",\n",
    "            \"goal\": \"Assign tasks to the team members and ensure the project is completed successfully.\",\n",
    "            \"backstory\": \"You are Nikola, the Team Lead. You are responsible for assigning tasks to the team members and ensuring that the project is completed successfully. You have a sharp scientific acument and a keen eye for detail.\",\n",
    "            \"allow_delegation\": True,\n",
    "            \"verbose\": True,\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"8\",\n",
    "            \"role\": \"Markdown Formatter Agent\",\n",
    "            \"goal\": \"Format the content in markdown format in an aesthetic and professional manner.\",\n",
    "            \"backstory\": \"You are Valmiki, a Markdown Formatter Agent. You format the content in markdown so that it is aesthetic and professional. You use the correct markdown elements for each section and ensure the content is well-structured.\",\n",
    "            \"allow_delegation\": False,\n",
    "            \"verbose\": True,\n",
    "        },\n",
    "    ],\n",
    "    \"tasks\": [\n",
    "        {\n",
    "            \"description\": \"Generate a detailed study titled '{topic}'\",\n",
    "            \"expected_output\": \"\"\"\"\n",
    "                    A detailed, factually correct, engaging and relevant study titled '{topic}' that is appropriate for a LinkedIn Newsletter audience.\n",
    "                    The post should be well formatted in markdown format with sections, subsections, and paragraphs per section. Use bullet points where necessary, but avoid nested bullet points.\n",
    "                    Each section should be detailed and self-contained. The study should be well-researched, insightful, and provide valuable takeaways for the readers.\n",
    "                    Provide citation links and sources at the end.\n",
    "                    User Guidance: {user_guidance}\n",
    "                            \"\"\",\n",
    "            \"tools\": [],\n",
    "            \"agent\": {\"id\": \"7\"},\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Crew to Generate Study\n",
    "\n",
    "This code defines a framework for running a \"crew\" of agents to generate a detailed study or research on a given topic, formatted in markdown. Here's an explanation of the key components:\n",
    "\n",
    "### 1. Imports\n",
    "\n",
    "- **`Agent`, `Task`, `Crew`, `LLM` from `crewai`**:  \n",
    "\n",
    "  These are classes used to define the agents, tasks, and the team (`crew`) responsible for executing the project. `LLM` refers to a language model like GPT-4.\n",
    "\n",
    "- **`SerperDevTool` from `crewai_tools`**:  \n",
    "\n",
    "  A tool that helps the agents access relevant data, like using a search engine.\n",
    "\n",
    "- **`BaseModel` from `pydantic`**:  \n",
    "\n",
    "  Used for defining input models that validate and structure data.\n",
    "\n",
    "- **`copy`**:  \n",
    "\n",
    "  Used to create copies of objects to avoid modifying the originals.\n",
    "\n",
    "- **`os`**:  \n",
    "\n",
    "  Used for accessing environment variables.\n",
    "\n",
    "### 2. `NAMOStudyCrewInput` Class\n",
    "\n",
    "This class is a `Pydantic` model that defines the required inputs for the \"crew\" to function. The inputs are:\n",
    "\n",
    "- **`topic`**:  \n",
    "\n",
    "  The topic on which the study is to be created.\n",
    "\n",
    "- **`user_guidance`**:  \n",
    "\n",
    "  Specific guidance or context that can influence the study creation.\n",
    "\n",
    "### 3. `run_crew_from_config` Function\n",
    "\n",
    "This is the core function that initializes the agents, tasks, and crew, and then runs the study creation process:\n",
    "\n",
    "#### Input Parameters:\n",
    "\n",
    "- **`input`**:  \n",
    "\n",
    "  An instance of `NAMOStudyCrewInput` that contains the topic and user guidance.\n",
    "\n",
    "- **`config`**:  \n",
    "\n",
    "  The configuration for the crew, agents, and tasks.\n",
    "\n",
    "- **`output_file`**:  \n",
    "\n",
    "  The file where the markdown study will be saved.\n",
    "\n",
    "#### Configuration Handling:\n",
    "\n",
    "- The function extracts the agents, tasks, and crew configurations from the `config` dictionary.\n",
    "\n",
    "- It creates a list of tools (`SerperDevTool`), which could be used by the agents for gathering data, and sets up an instance of `LLM` (language model) using the OpenAI API.\n",
    "\n",
    "#### Agent Initialization:\n",
    "\n",
    "- For each agent in the configuration, a new `Agent` object is created. The agent is initialized without its \"id\" field (which is not needed by the `Agent` class) and assigned the `llm` (language model).\n",
    "\n",
    "#### Task Initialization:\n",
    "\n",
    "- For each task in the configuration, the function creates a `Task` object. It removes the \"agent\" and \"tools\" fields from the task configuration, as these will be assigned separately.\n",
    "\n",
    "- It then matches the task's agent ID with one of the initialized agents and assigns the corresponding agent to the task.\n",
    "\n",
    "#### Crew Initialization:\n",
    "\n",
    "- The `Crew` object is initialized with the list of agents and tasks, along with memory and verbosity settings defined in the crew configuration.\n",
    "\n",
    "#### Crew Execution:\n",
    "\n",
    "- The `crew.kickoff()` method is called to execute the crew's tasks. The inputs (`topic` and `user guidance`) are passed to the crew.\n",
    "\n",
    "#### Result Handling:\n",
    "\n",
    "- After execution, the crew produces the result, which is expected to be raw markdown.\n",
    "\n",
    "- The result is saved to a file (**`namo_study.md`**).\n",
    "\n",
    "### Summary:\n",
    "\n",
    "The function **`run_crew_from_config`** is responsible for initializing the agents, tasks, and crew based on the configuration, running the study creation process, and saving the output in markdown format. The agents perform different roles (e.g., researching, analyzing, writing), and their collaboration generates a comprehensive study on the provided topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, LLM\n",
    "from crewai_tools import SerperDevTool\n",
    "from typing import Any\n",
    "from pydantic import BaseModel\n",
    "import copy\n",
    "import os\n",
    "\n",
    "\n",
    "class NAMOStudyCrewInput(BaseModel):\n",
    "    \"\"\"The input for the NAMO Study Crew.\"\"\"\n",
    "\n",
    "    topic: str\n",
    "    user_guidance: str\n",
    "\n",
    "\n",
    "def run_crew_from_config(\n",
    "    input: NAMOStudyCrewInput, config: Any, output_file=\"namo_study.md\"\n",
    ") -> None:\n",
    "    \"\"\"Runs the crew using the specified config and input data.\"\"\"\n",
    "    agents_config = config[\"agents\"]\n",
    "    tasks_config = config[\"tasks\"]\n",
    "    crew_config = config[\"crew\"]\n",
    "    tools = [SerperDevTool()]\n",
    "    llm = LLM(\n",
    "        model=\"openai/gpt-4o\",\n",
    "        temperature=0.84,\n",
    "        seed=12,\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    agents = []\n",
    "    for agent_config in agents_config:\n",
    "        agent_config_without_id = copy.deepcopy(agent_config)\n",
    "        del agent_config_without_id[\"id\"]\n",
    "        agent = Agent(**agent_config_without_id, llm=llm)\n",
    "        agents.append(agent)\n",
    "\n",
    "    tasks = []\n",
    "\n",
    "    for task_config in tasks_config:\n",
    "        task_config_without_agent = copy.deepcopy(task_config)\n",
    "        del task_config_without_agent[\"agent\"]\n",
    "        del task_config_without_agent[\"tools\"]\n",
    "        agent = None\n",
    "        for a in agents_config:\n",
    "            if a[\"id\"] == task_config[\"agent\"][\"id\"]:\n",
    "                agent_config_without_id = copy.deepcopy(a)\n",
    "                del agent_config_without_id[\"id\"]\n",
    "                agent = Agent(**agent_config_without_id, llm=llm, tools=tools)\n",
    "                break\n",
    "        print(agent)\n",
    "        task = Task(**task_config_without_agent, agent=agent)\n",
    "        tasks.append(task)\n",
    "\n",
    "    crew = Crew(\n",
    "        agents=agents,\n",
    "        tasks=tasks,\n",
    "        verbose=crew_config[\"verbose\"],\n",
    "        memory=crew_config[\"memory\"],\n",
    "    )\n",
    "\n",
    "    result = crew.kickoff(\n",
    "        inputs={\"user_guidance\": input.user_guidance, \"topic\": input.topic}\n",
    "    )\n",
    "    markdown = result.raw\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate Study Based on Configuration\n",
    "\n",
    "This code snippet sets up the configuration and input for generating a study based on the **`NAMO_STUDY_CREW_CONFIG`** configuration and runs the **`run_crew_from_config`** function to create the study. Here's a breakdown of how the code works:\n",
    "\n",
    "### 1. `deepcopy(NAMO_STUDY_CREW_CONFIG)`\n",
    "\n",
    "- The configuration **`NAMO_STUDY_CREW_CONFIG`** is deep-copied to ensure that any modifications to `config` don't affect the original **`NAMO_STUDY_CREW_CONFIG`**.\n",
    "\n",
    "- **`deepcopy`** is used here so that any changes made to `config` (such as modifying sections or agent configurations) will not impact the original configuration.\n",
    "\n",
    "### 2. Study Configuration Variables:\n",
    "\n",
    "- **`topic`**:  \n",
    "\n",
    "  This defines the topic for the study, which is **\"Learnings from Narendra Modi and Yogic Science for 2025\"**. It is the subject matter for the agents to work on.\n",
    "\n",
    "- **`version`**:  \n",
    "\n",
    "  The version of the study is set to **\"v1\"**, which can be used for version control or file naming.\n",
    "\n",
    "- **`section`**:  \n",
    "\n",
    "  This identifies the specific section of the study. In this case, it is **\"learnings_from_namo_and_yogic_science\"**, which can help organize content by different study areas.\n",
    "\n",
    "- **`file_name`**:  \n",
    "\n",
    "  This dynamically generates a filename based on the section and version variables. The result is something like **`namo_study__learnings_from_namo_and_yogic_science_v1.md`**, which will be used to save the output file.\n",
    "\n",
    "### 3. Output File Path:\n",
    "\n",
    "- **`output_file`**:  \n",
    "\n",
    "  This defines the path where the final markdown study will be saved. The file will be stored in the **`output/`** folder with the filename constructed earlier.\n",
    "\n",
    "### 4. Running the Crew with **`run_crew_from_config`**:\n",
    "\n",
    "The function **`run_crew_from_config`** is called to start the process. It is passed the following parameters:\n",
    "\n",
    "- **`config`**:  \n",
    "\n",
    "  The configuration (**`NAMO_STUDY_CREW_CONFIG`**) that defines the agents, tasks, and crew setup.\n",
    "\n",
    "- **`input`**:  \n",
    "\n",
    "  An instance of the **`NAMOStudyCrewInput`** class with the specified topic (**\"Learnings from Narendra Modi and Yogic Science for 2025\"**) and an empty **`user_guidance`**. The guidance could be used later to refine or specify the content based on user needs.\n",
    "\n",
    "- **`output_file`**:  \n",
    "\n",
    "  The output file path where the generated study (in markdown format) will be saved.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "This code sets up a specific study related to **Narendra Modi** and **Yogic Science**, creates a file path for the output, and then uses the **`run_crew_from_config`** function to generate the study. The study will be written in **markdown** and saved as a file in the **`output/`** directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "config = deepcopy(NAMO_STUDY_CREW_CONFIG)\n",
    "\n",
    "## Configure this as per each section of the study ebook\n",
    "topic = \"Learnings from Narendra Modi and Yogic Science for 2025\"\n",
    "version = \"v1\"\n",
    "section = \"learnings_from_namo_and_yogic_science\"\n",
    "\n",
    "file_name = f\"namo_study__{section}_{version}.md\"\n",
    "output_file = f\"output/{file_name}\"\n",
    "\n",
    "run_crew_from_config(\n",
    "    config=config,\n",
    "    input=NAMOStudyCrewInput(user_guidance=\"\", topic=topic),\n",
    "    output_file=output_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Elaborating Markdown Document\n",
    "\n",
    "This code defines a series of functions for elaborating sections of a **markdown** document by adding more detailed content. Here's a breakdown of the code’s structure and functionality:\n",
    "\n",
    "#### 1. `get_file_contents(file_path: str) -> str`:\n",
    "\n",
    "- **Reads** the content of a file at the given path and returns it as a string.\n",
    "- If the file cannot be read, it **catches the exception**, prints an error message, and returns an empty string.\n",
    "\n",
    "#### 2. `extract_current_section(markdown: str, section_title: str) -> str`:\n",
    "\n",
    "- This function **extracts** a section of the markdown document based on the **section title**.\n",
    "- The section is collected until the next section header (i.e., when a line starting with `#` appears).\n",
    "- The function returns the **content of the section**.\n",
    "\n",
    "#### 3. `get_markdown_sections_by_header(markdown: str) -> dict`:\n",
    "\n",
    "- This function splits the **markdown document** into individual sections by identifying **headers** (lines that start with `#`).\n",
    "- It stores each section's title and content in a **dictionary**, where the key is the section title and the value is the section content.\n",
    "- **Returns** a dictionary containing sections of the markdown document.\n",
    "\n",
    "#### 4. `elaborate_section(section_details: dict) -> dict`:\n",
    "\n",
    "- Given a section (**title and content**), it sends a request to the **Anthropomorphic LLM** (via the **anthropic.Client API**) to elaborate on the section.\n",
    "- The response contains additional insights, explanations, and details that **enrich** the original content.\n",
    "- The function **returns** a dictionary with the title and the refined content.\n",
    "\n",
    "#### 5. `elaborate_raw_document(sections: dict)`:\n",
    "\n",
    "- Loops through all sections and elaborates on them using the **`elaborate_section`** function.\n",
    "- Collects the elaborated sections and **returns** a dictionary of the refined sections.\n",
    "\n",
    "#### 6. `write_to_file(file_path: str, content: str)`:\n",
    "\n",
    "- **Writes** the provided content to a file at the given path.\n",
    "- If an error occurs while writing, it attempts to write to a **temporary file** instead.\n",
    "\n",
    "#### 7. `elaborate_document(title: str, file_path: str, output_file=\"refined_output.md\", write_output=True)`:\n",
    "\n",
    "- This is the **main function** for elaborating an entire document.\n",
    "- It reads the **markdown file**, extracts the sections, elaborates them, and then writes the refined content to a new file (if **`write_output`** is True).\n",
    "- It also logs the elaborated sections in a **JSON format** for debugging or record-keeping.\n",
    "\n",
    "### Key Functionalities:\n",
    "\n",
    "- **Anthropic LLM API**: The LLM is used to enhance sections of the document by providing more in-depth explanations and details.\n",
    "  \n",
    "- **Error Handling**: The code includes comprehensive **error handling** with tracebacks to ensure that if any step fails, the process continues smoothly, and errors are logged.\n",
    "  \n",
    "- **Markdown Processing**: The code works with **markdown files**, extracting sections, elaborating on them, and saving the updated content in a new markdown file.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "This approach helps in enhancing and elaborating an existing document, creating a more detailed and informative study, in this case, around a topic like **\"Learnings from Narendra Modi and Yogic Science for 2025\"**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate refined sections for a section\n",
    "import traceback\n",
    "import anthropic\n",
    "import os\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "llm = anthropic.Client(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "\n",
    "def get_file_contents(file_path: str) -> str:\n",
    "    try:\n",
    "        contents = \"\"\n",
    "        with open(file_path, \"r\") as f:\n",
    "            contents = f.read()\n",
    "        return contents\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get file contents for path: {file_path}.\")\n",
    "        traceback.print_exc()\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def extract_current_section(markdown: str, section_title: str) -> str:\n",
    "    \"\"\"Extacts the entire current section upto the next section header.\n",
    "\n",
    "    Example:\n",
    "    # Introduction\n",
    "    This is the introduction.\n",
    "\n",
    "    ## Background\n",
    "    This is the background.\n",
    "\n",
    "    ### Sub Background\n",
    "    This is the sub background.\n",
    "\n",
    "    Output:\n",
    "    {\n",
    "        \"# Introduction\": This is the introduction.\\n\\n\",\n",
    "        \"## Background\": This is the background.\\n\\n\",\n",
    "        \"### Sub Background\\\": his is the sub background.\\n\\n\"\n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    section = \"\"\n",
    "    remaining_markdown = markdown.split(section_title)[1]\n",
    "    remaining_markdown = remaining_markdown.split(\"\\n\")\n",
    "    for line in remaining_markdown:\n",
    "        # print(f\"Line: {line}\")\n",
    "        if line.startswith(\"#\") and line != section_title:\n",
    "            break\n",
    "        section += line + \"\\n\"\n",
    "    return section\n",
    "\n",
    "\n",
    "def get_markdown_sections_by_header(markdown: str) -> dict:\n",
    "    \"\"\"Gets the sections of the markdown based on the header.\"\"\"\n",
    "    try:\n",
    "        sections = {}\n",
    "        current_section = \"\"\n",
    "        lines = markdown.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            if line.startswith(\"#\"):\n",
    "                current_section = line\n",
    "                content = extract_current_section(markdown, current_section)\n",
    "                sections[current_section] = content + \"\\n\"\n",
    "            else:\n",
    "                continue\n",
    "        return sections\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get markdown sections.\")\n",
    "        traceback.print_exc()\n",
    "        return {}\n",
    "\n",
    "\n",
    "def elaborate_section(section_details: dict) -> dict:\n",
    "    \"\"\"Elaborates the section by adding more content to it.\"\"\"\n",
    "    try:\n",
    "        section_title = section_details.get(\"title\")\n",
    "        section_content = section_details.get(\"content\")\n",
    "        if section_title is None or section_content is None:\n",
    "            print(f\"Section title or content is missing.\")\n",
    "            return {\"title\": None, \"content\": None}\n",
    "        system = f\"\"\"\n",
    "            You are NAMO (Narendra Modi) Study AI. You have been tasked with elaborating the section titled '{section_title}'.\n",
    "            Your goal is to provide more detailed insights and information related to this section.\n",
    "            Avoid hallucination and don't make up factual information.\n",
    "            Add details to the section, explain concepts in simple language, and add facts to support your explanations.\n",
    "            Provide the response in a well-structured markdown format. \n",
    "            This section will go into a larger study ebook.\n",
    "            So make sure it logically flows with the existing content.\n",
    "\n",
    "            INSTRUCTIONS:\n",
    "            - If there's a bullet point you need to elaborate, replace the bullet point with 3-4 lines. \n",
    "            The first line is the fact. The 2nd and 3rd line explains the fact and the 4th line is an example or some valid data point if available (don't make up stats).\n",
    "            - If it's a pargraph, leave it untouched. \n",
    "        \"\"\"\n",
    "        user_prompt = f\"\"\"\n",
    "            Elaborate the section titled '{section_title}'.\n",
    "            Existing Content: {section_content}\n",
    "        \"\"\"\n",
    "        message = llm.messages.create(\n",
    "            model=\"claude-3-5-sonnet-latest\",\n",
    "            temperature=0.5,\n",
    "            max_tokens=4096,\n",
    "            system=system,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": user_prompt}],\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "        return {\"title\": section_title, \"content\": message.content[0].text}\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to elaborate section: {section_title}.\")\n",
    "        traceback.print_exc()\n",
    "        return {\"title\": None, \"content\": None}\n",
    "\n",
    "\n",
    "def elaborate_raw_document(sections: dict):\n",
    "    \"\"\"Elaborates the raw document by adding more content to each section.\"\"\"\n",
    "    elaborated_sections = {}\n",
    "    for title, content in sections.items():\n",
    "        try:\n",
    "            print(f\"Elaborating section: {title}\")\n",
    "            section_details = {\"title\": title, \"content\": content}\n",
    "            elaborated_section = elaborate_section(section_details)\n",
    "            elaborated_title = elaborated_section.get(\"title\")\n",
    "            elaborated_section = elaborated_section.get(\"content\")\n",
    "\n",
    "            if not elaborated_title or not elaborated_section:\n",
    "                print(f\"Failed to elaborate section: {title}.\")\n",
    "                continue\n",
    "\n",
    "            elaborated_sections[elaborated_title] = elaborated_section\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to elaborate section: {title}.\")\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    return elaborated_sections\n",
    "\n",
    "\n",
    "def write_to_file(file_path: str, content: str):\n",
    "    try:\n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.write(content)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to write content to file: {file_path}.\")\n",
    "        traceback.print_exc()\n",
    "        print(\"Fallback rewrite to temp file to preserve output.\")\n",
    "        try:\n",
    "            temp_file = f\"temp_{datetime.now().strftime('%Y%m%d%H%M%S')}.md\"\n",
    "            with open(temp_file, \"w\") as f:\n",
    "                f.write(content)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to write content to temp file.\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "\n",
    "def elaborate_document(\n",
    "    title: str, file_path: str, output_file=\"refined_output.md\", write_output=True\n",
    ") -> None:\n",
    "    \"\"\"Elaborates the document by adding more content to each section.\"\"\"\n",
    "    markdown = get_file_contents(file_path)\n",
    "    if not markdown:\n",
    "        print(\"No content found in the file.\")\n",
    "        return\n",
    "    sections = get_markdown_sections_by_header(markdown)\n",
    "\n",
    "    if len(sections.keys()) == 0:\n",
    "        print(\"No sections found in the document.\")\n",
    "        return\n",
    "\n",
    "    elaborated_sections = elaborate_raw_document(sections)\n",
    "    log_json = json.dumps(elaborated_sections, indent=4)\n",
    "    print(f\"Elaborated sections: {log_json}\")\n",
    "    new_markdown = f\"# {title}\\n\\n\"\n",
    "    for section_title, content in elaborated_sections.items():\n",
    "        new_markdown += section_title + \"\\n\" + content + \"\\n\"\n",
    "        new_markdown += \"---\\n\"\n",
    "    if write_output:\n",
    "        print(f\"Writing elaborated content to file: {output_file}\")\n",
    "        write_to_file(output_file, new_markdown)\n",
    "        print(f\"Elaborated content written to file: {output_file}\")\n",
    "    print(\"Elaboration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Overview of Markdown Elaboration Process\n",
    "\n",
    "This code is part of a script for processing a **`markdown`** file that elaborates on a topic related to **`Narendra Modi`** and **`Yogic Science`**. Here’s a breakdown of what each part does:\n",
    "\n",
    "### Variables Setup:\n",
    "\n",
    "- **`topic`**: The topic you want to explore, which is about the learnings from **Narendra Modi** and **Yogic Science** for the year 2025.\n",
    "\n",
    "- **`folder_version`** and **`version`**: These variables are used for managing different versions of the file (e.g., **v1**).\n",
    "\n",
    "- **`section`**: A specific section of the study that you're working on (e.g., **learnings_from_namo_and_yogic_science**).\n",
    "\n",
    "### File Paths:\n",
    "\n",
    "- **`file_name`**: This generates the filename for the raw input markdown based on the topic section and version (e.g., **namo_study__learnings_from_namo_and_yogic_science_v1.md**).\n",
    "  \n",
    "- **`input_file`**: The full path for the raw markdown file, which is located in the **output/{folder_version}/raw/** directory.\n",
    "  \n",
    "- **`output_file_name`**: A filename for the **refined markdown output** (e.g., **namo_study__learnings_from_namo_and_yogic_science_v1_refined.md**).\n",
    "  \n",
    "- **`output_file`**: The full path for the refined markdown file that will be saved in the **output/{folder_version}/refined/** directory.\n",
    "\n",
    "### Elaboration Process:\n",
    "\n",
    "- The **`elaborate_document()`** function is called to process the input file (**input_file**), elaborate on its sections, and save the updated content to the **output_file**.\n",
    "\n",
    "### What Happens Next:\n",
    "\n",
    "- The **`elaborate_document()`** function processes the file by first **reading the content** from the specified **input_file**.\n",
    "  \n",
    "- Then, it **splits** the content into sections, elaborates each section using the **`elaborate_section()`** function, and combines the refined sections into a new **markdown document**.\n",
    "  \n",
    "- The newly created file is **saved** at the location specified by **output_file**, and the elaborated content will be written to this file.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "This approach helps in refining and enhancing the original content by adding in-depth elaborations and insights. The final result is a **well-researched and enriched study** on the topic, saved in a new markdown file for further use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Learnings from Narendra Modi and Yogic Science for 2025\"\n",
    "folder_version = \"v1\"\n",
    "version = \"v1\"\n",
    "section = \"learnings_from_namo_and_yogic_science\"\n",
    "\n",
    "file_name = f\"namo_study__{section}_{version}.md\"\n",
    "input_file = f\"output/{folder_version}/raw/{file_name}\"\n",
    "output_file_name = f\"namo_study__{section}_{version}_refined.md\"\n",
    "output_file = f\"output/{folder_version}/refined/{output_file_name}\"\n",
    "\n",
    "elaborate_document(topic, input_file, output_file=output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "The **NAMO Study App** aims to provide a comprehensive, well-structured exploration of the teachings and insights from **Narendra Modi** and **Yogic Science**, with a particular focus on their potential implications for **2025**. By leveraging **AI-driven tools** for content refinement and elaboration, this app enhances the depth and quality of the content, ensuring that each section is thoroughly elaborated while maintaining logical coherence with the overall study.\n",
    "Through the integration of **anthropic AI (Claude)** and **Markdown processing**, the app provides a systematic approach to:\n",
    "### `Content Extraction`:\n",
    "- Efficiently pulling out sections of text and ensuring they are appropriately segmented for easy expansion.\n",
    "\n",
    "#### `Content Elaboration`:\n",
    "- Adding meaningful, fact-based insights to each section, enhancing the original content without introducing unnecessary details or hallucinations.\n",
    "\n",
    "#### `Output Formatting`:\n",
    "- Generating well-organized, polished **markdown files** that can be directly used in an **ebook** or other forms of documentation.\n",
    "\n",
    "The app serves as an indispensable tool for anyone looking to create rich, detailed, and insightful content based on structured input, making it easier to transform raw content into an **informative study** or **report**. By automating the elaboration process, it saves time while providing a more refined, readable output suitable for educational or professional purposes.\n",
    "\n",
    "This approach can be generalized to various topics and adapted to different use cases, positioning the **NAMO Study App** as a **versatile tool** in **content creation**, **research**, and **knowledge management** for the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Thank You for visiting The Hackers Playbook! 🌐\n",
    "\n",
    "If you liked this research material;\n",
    "\n",
    "- [Subscribe to our newsletter.](https://thehackersplaybook.substack.com)\n",
    "\n",
    "- [Follow us on LinkedIn.](https://www.linkedin.com/company/the-hackers-playbook/)\n",
    "\n",
    "- [Leave a star on our GitHub.](https://www.github.com/thehackersplaybook)\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
